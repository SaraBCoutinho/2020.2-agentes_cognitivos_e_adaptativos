{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraBCoutinho/2020.2-agentes_cognitivos_e_adaptativos/blob/main/LIAR_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n693279s2TTl"
      },
      "source": [
        "### Introduçao "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkpgivSt2QyA"
      },
      "source": [
        "Sites: \n",
        "\n",
        "https://huggingface.co/datasets/liar \n",
        "\n",
        "https://www.kaggle.com/c/fake-news/data\n",
        "\n",
        "https://github.com/mansoor9743/Fake-News-Detection/blob/master/code/Fake_news_detection.ipynb\n",
        "\n",
        "https://github.com/ekagra-ranjan/fake-news-detection-LIAR-pytorch/blob/master/data.py\n",
        "\n",
        "https://www.kaggle.com/clmentbisaillon/classifying-fake-news-with-bert \n",
        "\n",
        "https://www.youtube.com/watch?v=lwZgvzw6YCs\n",
        "\n",
        "https://stackoverflow.com/questions/50184280/how-to-conceptually-think-about-relationship-between-tokenized-words-and-word-em, \n",
        "\n",
        "https://github.com/hmohebbi/SentimentAnalysis/blob/master/main.ipynb USADO \n",
        "\n",
        "https://www.quora.com/What-are-the-main-differences-between-the-word-embeddings-of-ELMo-BERT-Word2vec-and-GloVe LER PARA DUVIDAS \n",
        "\n",
        "!pip install  https://docs.python.org/3.8/library/itertools.html#module-itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B9Cz9Oz58Z-"
      },
      "source": [
        "No experimento, reproduzir. O dataset nao precisa criar os k folds porque nao faz o cross validation, os conjuntos de treino e teste ja sao definidos e usados na literatura. O tratamento dos dados vai de acordo com a literatura. Foram usados os statement como x e label como y. Além disso, 6 representaçoes (inovando com o bert) e mais 8 classificadores, totalizando 48 resultados. \n",
        "Depois feita a binarizaçao e re-reproduçao do experimento. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DUbfTOa8o9z"
      },
      "source": [
        "Duvidas: o selectorKbest no pipeline p/ tfidf e cv ; comparativo quando nao se tem muita diferença usando a matriz de confusao. Uso de Bernoulli e Multinomial em NB . No diversity analysis nao gerei os folds, ver se as funçoes sao retiradas. Duvida no fine-tuning do Bert. Methods, no diversity analysis, seriam as prediçoes? Na verdade ver o X e y e  a parte de label e methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWDRpPl_U2_z"
      },
      "source": [
        "Possivel bert: https://medium.com/@vslovik/fake-news-detection-empowered-with-bert-and-friends-20397f7e1675 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oQkWINzWg4wq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSKt1A_hfZLy"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rEB0MKIYfbfz",
        "outputId": "65bbf0f9-9f18-42ca-cb4a-c1ee3c1d3e5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 15.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 476 kB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 60.9 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.9)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 38.2 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 58.3 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, huggingface-hub, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=2083e73ec80a39aecbb5df9786b52afe381b3c1fb3a34b2ebfc541de2fe78133\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Collecting zeugma\n",
            "  Downloading zeugma-0.49.tar.gz (9.9 kB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (1.19.5)\n",
            "Requirement already satisfied: Cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (0.29.24)\n",
            "Requirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (1.1.5)\n",
            "Requirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from zeugma) (3.6.0)\n",
            "Requirement already satisfied: scikit_learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from zeugma) (1.0.1)\n",
            "Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from zeugma) (2.7.0)\n",
            "Requirement already satisfied: keras>=2.1.3 in /usr/local/lib/python3.7/dist-packages (from zeugma) (2.7.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.5.0->zeugma) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.5.0->zeugma) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.5.0->zeugma) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->zeugma) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->zeugma) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.19.1->zeugma) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.19.1->zeugma) (3.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.13.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.22.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (12.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.37.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (1.42.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.5.0->zeugma) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=1.5.0->zeugma) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=1.5.0->zeugma) (3.1.1)\n",
            "Building wheels for collected packages: zeugma\n",
            "  Building wheel for zeugma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zeugma: filename=zeugma-0.49-py3-none-any.whl size=8821 sha256=bb378955cc5bcaa16789d0892572a2eb6473dbc26bb7e0ee8dd4a691ec335a37\n",
            "  Stored in directory: /root/.cache/pip/wheels/1d/47/5b/2a59a79706cc9340c72fd6a7bfc20e7ebcab849c88c38fdfa0\n",
            "Successfully built zeugma\n",
            "Installing collected packages: zeugma\n",
            "Successfully installed zeugma-0.49\n",
            "Collecting preprocessing\n",
            "  Downloading preprocessing-0.1.13-py3-none-any.whl (349 kB)\n",
            "\u001b[K     |████████████████████████████████| 349 kB 13.8 MB/s \n",
            "\u001b[?25hCollecting sphinx-rtd-theme==0.2.4\n",
            "  Downloading sphinx_rtd_theme-0.2.4-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.2.4\n",
            "  Downloading nltk-3.2.4.tar.gz (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.2.4->preprocessing) (1.15.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.2.4-py3-none-any.whl size=1367721 sha256=9612a485de64583fb42ebaa344b9e43fb5bdf02be7e740effa27868911df6864\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/5e/9e/4cb46185f2a16c60e6fc524372ba7fef89ce3347734c8798b6\n",
            "Successfully built nltk\n",
            "Installing collected packages: sphinx-rtd-theme, nltk, preprocessing\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.2.4 preprocessing-0.1.13 sphinx-rtd-theme-0.2.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting function\n",
            "  Downloading function-1.2.0.tar.gz (766 bytes)\n",
            "Building wheels for collected packages: function\n",
            "  Building wheel for function (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for function: filename=function-1.2.0-py3-none-any.whl size=1463 sha256=67655cf420f7867b2bca89a184ff100a3850b619538e992fc5309c4321658dea\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ac/86/0db3a8b76385994e22ec07808657e3584de609026808a32ca6\n",
            "Successfully built function\n",
            "Installing collected packages: function\n",
            "Successfully installed function-1.2.0\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.3 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.0\n",
            "Collecting bert_embedding\n",
            "  Downloading bert_embedding-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting typing==3.6.6\n",
            "  Downloading typing-3.6.6-py3-none-any.whl (25 kB)\n",
            "Collecting mxnet==1.4.0\n",
            "  Downloading mxnet-1.4.0-py2.py3-none-manylinux1_x86_64.whl (29.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.6 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting numpy==1.14.6\n",
            "  Downloading numpy-1.14.6-cp37-cp37m-manylinux1_x86_64.whl (13.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 49.4 MB/s \n",
            "\u001b[?25hCollecting gluonnlp==0.6.0\n",
            "  Downloading gluonnlp-0.6.0.tar.gz (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert_embedding) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet==1.4.0->bert_embedding) (0.8.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->mxnet==1.4.0->bert_embedding) (2021.10.8)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.6.0-py3-none-any.whl size=259930 sha256=b2cd96359cc812311cc9eec60c294c1db64807c143a32a8b6e6a3a2c1457ffbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/41/8f/45bd1c58055d87aee5a71b6756a427ea8d92e506b3a9d17370\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: numpy, typing, mxnet, gluonnlp, bert-embedding\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: mxnet\n",
            "    Found existing installation: mxnet 1.9.0\n",
            "    Uninstalling mxnet-1.9.0:\n",
            "      Successfully uninstalled mxnet-1.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "tifffile 2021.11.2 requires numpy>=1.15.1, but you have numpy 1.14.6 which is incompatible.\n",
            "spacy 2.2.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "seaborn 0.11.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.14.6 which is incompatible.\n",
            "pywavelets 1.2.0 requires numpy>=1.17.3, but you have numpy 1.14.6 which is incompatible.\n",
            "pymc3 3.11.4 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "pyarrow 3.0.0 requires numpy>=1.16.6, but you have numpy 1.14.6 which is incompatible.\n",
            "plotnine 0.6.0 requires numpy>=1.16.0, but you have numpy 1.14.6 which is incompatible.\n",
            "pandas 1.1.5 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n",
            "numba 0.51.2 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "librosa 0.8.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.14.6 which is incompatible.\n",
            "jaxlib 0.1.71+cuda111 requires numpy>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "jax 0.2.25 requires numpy>=1.18, but you have numpy 1.14.6 which is incompatible.\n",
            "imgaug 0.2.9 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "fbprophet 0.7.1 requires numpy>=1.15.4, but you have numpy 1.14.6 which is incompatible.\n",
            "fastai 1.0.61 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "datasets 1.17.0 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "cvxpy 1.0.31 requires numpy>=1.15, but you have numpy 1.14.6 which is incompatible.\n",
            "blis 0.4.1 requires numpy>=1.15.0, but you have numpy 1.14.6 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.14.6 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed bert-embedding-1.0.1 gluonnlp-0.6.0 mxnet-1.4.0 numpy-1.14.6 typing-3.6.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mxnet",
                  "numpy",
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#--Data\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "#--Data analysis \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "!pip install ftfy\n",
        "# import libraries\n",
        "import ftfy\n",
        "import nltk\n",
        "import json\n",
        "import re\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import nltk\n",
        "import seaborn as sb\n",
        "import warnings\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "from collections import Counter\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join, splitext, split\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from nltk import pos_tag\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "from wordcloud import STOPWORDS, WordCloud\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier # need to import xboost calssifer\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(0)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# stop words list set to english\n",
        "stopwords_list = stopwords.words('english') # stop word list\n",
        "\n",
        "\"\"\" Regular expression for cleaning the statements\"\"\"\n",
        "import re\n",
        "\n",
        "hashtag_re = re.compile(r\"#\\w+\")\n",
        "mention_re = re.compile(r\"@\\w+\")\n",
        "url_re = re.compile(r\"(?:https?://)?(?:[-\\w]+\\.)+[a-zA-Z]{2,9}[-\\w/#~:;.?+=&%@~]*\")\n",
        "extras_re = re.compile(\"[.;:!\\'?,\\\"()\\[\\]]\")\n",
        "#apos_re = \"\\'[a-z]*\"\n",
        "#leftover_re = \"\\S+\"\n",
        "\n",
        "from unicodedata import normalize\n",
        "\n",
        "!pip install zeugma\n",
        "!pip install preprocessing\n",
        "!pip install function\n",
        "\n",
        "from zeugma.embeddings import EmbeddingTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from preprocessing import *\n",
        "from function import *\n",
        "\n",
        "#!pip install itertools\n",
        "import itertools\n",
        "!pip install mxnet\n",
        "import mxnet as mx\n",
        "!pip install bert_embedding\n",
        "from bert_embedding import BertEmbedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFUxgNvQlxXk"
      },
      "source": [
        "### Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "abffa58378414868a596c9877b68480d",
            "8aefd848688a48e1a0161f26a5d92e17",
            "2354c5d783ea47a581c50d2b89efdd41",
            "59bbbe48656d43fdaa3cc3238bad9d6e",
            "88b2dea02e2c4cd39e269544d1b6343a",
            "bc5852439078473f9e18f70838870903",
            "6f87da839c194548bf5373ded49031d4",
            "409791b5baab4b20bd2273387ccfa42e",
            "4482920085ee4ef9adfa93c29aa148da",
            "7df972fa53364f838449907908d4283a",
            "075f1e2d50894dd280e6eade39f5f13f",
            "95db8eeca9a742898be5edb085dfed29",
            "dba63ea2c583412484434602e3c53802",
            "3e2bb1f86d624c15bdd3b8b43cdad558",
            "223f0b861f6a409bab86811b7ba8eabc",
            "21a77b3015c54aeca55117ce09bcfc44",
            "e2f600dae54a42dfa58e04d7518d9d20",
            "a9319f1058b54726a9ad03245405d9f1",
            "bfee3a19bc7042c5bcde541ccc410e44",
            "1502946c43f6438fb7849d67d5b73a9e",
            "6ba702c243194c3cb86bc04e1649295f",
            "000b3b353edb4a9d8894eb64d57cea85",
            "65d27b3f4e664af8bf5865fab5729fd5",
            "fe202ffd42c34a9e963068d47c57d630",
            "feb2c1dc15c7431cabe04863e9d68ad4",
            "7c5cbf918226461dbbcd247d171bcfed",
            "190db26640f04851b7ee6d09db179aef",
            "15715bfb8fec48408823bbde096d0b04",
            "1b6cd5cf0f2e4496a63744e2ba9291c1",
            "448c1dddde4c4da0acf25f38a4758288",
            "27f30893cd5e483095350bd37ee48f34",
            "02400aa009cb4cae928335ff788cc9bc",
            "21142b95acff4d209c92d89160f28e04",
            "fab994bbe1a547dcb4b6ff7a972df0bb",
            "867959911fea40da88bd4e139c8ad2b3",
            "46255ddacb544faebd913a229f676c11",
            "4d2ddd01928042e6bb7c94acfa473381",
            "596c34e1416e45d4934c954998eeb1a7",
            "3aa4a01d43d44d498fb6c4b3738db511",
            "16ee1d781f894613af37fc4f4c22d1f3",
            "4ac0b37eb98c4025916b31353d485231",
            "b46653b9e3f843c1b29dd842b633bb08",
            "c19b582204c045feb64ac0dd0737a200",
            "5bbee970689640488aafc44260794f06",
            "c19fc6db6bb94d4dae1a1927c7b9dc19",
            "56ab9f7e95e24eb480592fa662579d3c",
            "a58d1824c8d2403a88000aa0a1b40a73",
            "d35ec4a7e7454cf382c46160b2323ab5",
            "d13559e54a09465eb460c676c2b96b80",
            "472b4484fe3b4da3aaefd86b3396d85c",
            "7d59047c681c40b296c0c6995f13f846",
            "2b4d45012ffd4f48b4304270726446b0",
            "a38b517388c040e79f58815e69c4de35",
            "234d8553efc741499a4c04d80fa16740",
            "d169e26994a2478abd5de445eab29e2d",
            "0361234090894c7785c1f25a451b3713",
            "7f7abc2a1e6a489d99d916ec65db21f8",
            "b3fd1b52a7a64dfc89ad89c4104a324e",
            "5e74b2c5c0fb47b393c0bf976d6e147f",
            "db8a090a1d894a85a9f9acf623357fb1",
            "5e09b7217a4b47fcaf6fa44531444d7a",
            "95b378fb1d274dcbb695f4cf3ad31e5d",
            "106886a9f2e942899a8587f76d12a581",
            "72d3da2864de4014852d5f2662ffa328",
            "2549fa3e6bbe4543b671a29f6dc49e65",
            "3d0a2a1a26ff4274813bd3ffdb36d54a",
            "3d660278bce64469a49c46d8a5dff5fb",
            "9e10f5c909f249bca177f6ad178b8e8e",
            "65bb41b661794bd9ab15d8afff5c5389",
            "9e38e38d9a384510a311a5f2c7b9bc4e",
            "b645087427524d8586ca41811d6b6510",
            "8d2e28b39d164f8d96934fe38c1ec50c",
            "d08627a111084aa58c89658fe1987ff5",
            "f845f91521c94e269344f490be498eb2",
            "20e6ba394c6c4070b4a724b637e21dba",
            "a3ddf38054964ac2a1e732ef7d959619",
            "3ad97632bb5445c0ace32ace7de24048"
          ]
        },
        "id": "0SZvJB5NejzO",
        "outputId": "5e3adccb-d593-42e0-9fee-012df677f040"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abffa58378414868a596c9877b68480d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.33k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95db8eeca9a742898be5edb085dfed29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset liar/default (download: 989.82 KiB, generated: 3.26 MiB, post-processed: Unknown size, total: 4.22 MiB) to /root/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65d27b3f4e664af8bf5865fab5729fd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.01M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fab994bbe1a547dcb4b6ff7a972df0bb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c19fc6db6bb94d4dae1a1927c7b9dc19",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0361234090894c7785c1f25a451b3713",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset liar downloaded and prepared to /root/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d660278bce64469a49c46d8a5dff5fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset('liar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amaDQSZHGEa5"
      },
      "source": [
        "#### Pre processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIJfIa7BHCSV",
        "outputId": "958bff3a-2ca1-40f4-c499-07e28cafdf1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10269, 14) (1283, 14) (1284, 14)\n"
          ]
        }
      ],
      "source": [
        "#data\n",
        "train=pd.DataFrame(dataset['train'])\n",
        "test=pd.DataFrame(dataset['test'])\n",
        "val=pd.DataFrame(dataset['validation'])\n",
        "print(train.shape,test.shape,val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3VEgX0YTRrQ"
      },
      "source": [
        "label_to_number_6_way_classification = {'pants-fire': 0,'false': 1,'barely-true': 2,'half-true': 3,'mostly-true': 4,'true': 5}\n",
        "\n",
        "label_to_number_2_way_classification = {'pants-fire': 0,'false': 0,'barely-true': 0,'half-true': 1,'mostly-true': 1,'true': 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q1-LHpzmUl5U"
      },
      "outputs": [],
      "source": [
        "Original_labels={5:1, 4:1, 3:1, 1:0,2:0,0:0}\n",
        "train['label'] = train['label'].map(Original_labels)\n",
        "test['label'] = test['label'].map(Original_labels)\n",
        "val['label'] = val['label'].map(Original_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EXmeQZqQIZYp"
      },
      "outputs": [],
      "source": [
        "df_raw = pd.concat([train, test, val], axis=0, sort=False)\n",
        "df_raw = df_raw.sample(frac=1).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train['label'].unique())\n",
        "print(test['label'].unique())\n",
        "print(val['label'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUY4jeZ193EM",
        "outputId": "859a3bc5-b055-4280-d3c4-a790b878c92b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n",
            "[1 0]\n",
            "[1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-buRdxfO7LR"
      },
      "source": [
        "#### Divisao X e Y "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OfFMWr-j_taa"
      },
      "outputs": [],
      "source": [
        "# specifying features and labels\n",
        "X= df_raw['statement']\n",
        "y=df_raw['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2nB_iMnO92X"
      },
      "source": [
        "#### Divisao Treino e teste "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2xScQ49_wKV",
        "outputId": "556e674a-f884-4861-b5fb-13722d064661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10268 2568\n",
            "10268 2568\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# specifying train and test split with ratio of 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 0, stratify=y)\n",
        "print(len(X_train), len(X_test))\n",
        "print(len(y_train), len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg4ECprXPFI4"
      },
      "source": [
        "#### Pre processamento "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Fw7OHarDPEoI"
      },
      "outputs": [],
      "source": [
        "\"\"\" Preprocessing the text in the statements\"\"\"\n",
        "def preprocess(text):\n",
        "    p_text = hashtag_re.sub(\"[hashtag]\",text)\n",
        "    p_text = mention_re.sub(\"[mention]\",p_text)\n",
        "    p_text = extras_re.sub(\"\",p_text)\n",
        "    p_text = url_re.sub(\"[url]\",p_text) #removing url\n",
        "    p_text = ftfy.fix_text(p_text)\n",
        "    return p_text.lower()\n",
        "\n",
        "# regular expression for custom tokenisation\"\n",
        "tokenise_re = re.compile(r\"(\\[[^\\]]+\\]|[-'\\w]+|[^\\s\\w\\[']+)\") #([]|words|other non-space)\n",
        "\n",
        "# defining 3 types of tokenisation\n",
        "\n",
        "def custom_tokenise(text):\n",
        "    return tokenise_re.findall(text.lower())\n",
        "\n",
        "def Tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    porter_stemmer=nltk.PorterStemmer()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words\n",
        "\n",
        "\n",
        "def nltk_twitter_tokenise(text):\n",
        "    twtok = nltk.tokenize.TweetTokenizer()\n",
        "    return twtok.tokenize(text.lower())\n",
        "\n",
        "# stop words list set to english\n",
        "#stopwords_list = stopwords.words('english') # stop word list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyavtQwXPJpM"
      },
      "source": [
        "#### Métricas "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uboIHBCG_3CC"
      },
      "outputs": [],
      "source": [
        "# function for results of cross-validation\n",
        "def print_cv_scores_summary(name, scores):\n",
        "    print(\"{}: mean = {:.2f}%, sd = {:.2f}%, min = {:.2f}, max = {:.2f}\".format(name, scores.mean()*100, scores.std()*100, scores.min()*100, scores.max()*100))\n",
        "\n",
        "\n",
        "# fucntion for results of model fitting\n",
        "def print_scores():\n",
        "    print(\"Accuracy: \", accuracy_score(y_test, predictions))\n",
        "    print(classification_report(y_test, predictions))\n",
        "    print(confusion_matrix(y_test, predictions))\n",
        "    \n",
        "# function for displaying confusion matrix\n",
        "def confusion_matrix_heatmap(cm, index):\n",
        "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
        "    dims = (10, 8)\n",
        "    fig, ax = plt.subplots(figsize=dims)\n",
        "    sns.heatmap(cmdf, annot=True, cmap=\"BuPu\", center=0, fmt='g')\n",
        "    ax.set_ylabel('Actual')    \n",
        "    ax.set_xlabel('Predicted')\n",
        "\n",
        "# function for displaying confusion matrix in percentage terms\n",
        "def confusion_matrix_percent_heatmap(cm, index):\n",
        "    cmdf = pd.DataFrame(cm, index = index, columns=index)\n",
        "    percents = cmdf.div(cmdf.sum(axis=1), axis=0)*100\n",
        "    dims = (10, 10)\n",
        "    fig, ax = plt.subplots(figsize=dims)\n",
        "    sns.heatmap(percents, annot=True, cmap=\"PiYG\", center=0, vmin=0, vmax=100)\n",
        "    ax.set_ylabel('Actual')    \n",
        "    ax.set_xlabel('Predicted')\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.set_ticks([0, 25, 50, 75, 100])\n",
        "    cbar.set_ticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
        "    \n",
        "#list(df_columns.columns))-list(df_raw['labels'])\"coolwarm\"'Blues'PiYG'BuPu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vm0CKXuPOAF"
      },
      "source": [
        "#### Modelos 2 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wciTWAusptI4"
      },
      "source": [
        "###### Embeddings \n",
        "\n",
        "Bag of words: TF , TF IDF\n",
        "\n",
        "Dense Word Embeddings : Glove, Word2Vec, Fast Text \n",
        "\n",
        "Proposta : Bert (retirar camadas finais) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHnUHSYJp96_"
      },
      "source": [
        "Dense Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oafuIhAAOEnq",
        "outputId": "87c744e3-ed14-47ed-89e4-4a789b88afed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "w2v = EmbeddingTransformer('word2vec')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe1lTRZNOG8F",
        "outputId": "4c56833d-3b64-48d0-adce-de788c9eddff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "glove = EmbeddingTransformer('glove')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkhNrOESOIrp",
        "outputId": "6ef3d2f9-38b0-4345-a6c3-8397c6081091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ],
      "source": [
        "fasttext = EmbeddingTransformer('fasttext')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x1Y2m0r0rFRr"
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer(analyzer='word', lowercase=True, stop_words='english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OIY_LEyjr__H"
      },
      "outputs": [],
      "source": [
        "tfidf =  TfidfVectorizer(analyzer='word', lowercase=True, use_idf=True, stop_words='english')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning before BERT\n",
        "embedding = 'BERT'"
      ],
      "metadata": {
        "id": "3ztWkStYTs1n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean(z): # used for BERT (word version) and Word2Vec\n",
        "    return sum(itertools.chain(z))/len(z)"
      ],
      "metadata": {
        "id": "HusCj21mUeZG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embeddToBERT(text):\n",
        "    sentences = re.split('!|\\?|\\.',text)\n",
        "    sentences = list(filter(None, sentences)) \n",
        "\n",
        "    if bert_version == 'WORD':\n",
        "        result = bert(sentences, 'avg') # avg is refer to handle OOV\n",
        "    \n",
        "        bert_vocabs_of_sentence = []\n",
        "        for sentence in range(len(result)):\n",
        "            for word in range(len(result[sentence][1])):\n",
        "                bert_vocabs_of_sentence.append(result[sentence][1][word])\n",
        "        feature = [mean(x) for x in zip(*bert_vocabs_of_sentence)]\n",
        "\n",
        "    elif bert_version == 'SENTENCE':\n",
        "        result = bert_transformers.encode(sentences)\n",
        "        feature = [mean(x) for x in zip(*result)]\n",
        "  \n",
        "    return feature"
      ],
      "metadata": {
        "id": "AbbaJ4n1Ts72"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert = BertEmbedding()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJWmeSsR_zS4",
        "outputId": "a7400a0d-9697-401e-a936-0688f93e1eb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab file is not found. Downloading.\n",
            "Downloading /root/.mxnet/models/book_corpus_wiki_en_uncased-a6607397.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/book_corpus_wiki_en_uncased-a6607397.zip...\n",
            "Downloading /root/.mxnet/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip32e43083-9df8-4f93-a3a8-5c2e331877c4 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_book_corpus_wiki_en_uncased-75cc780f.zip...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_version = 'WORD'"
      ],
      "metadata": {
        "id": "SqjepM6qRBcl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_word_training_features = X_train.apply(embeddToBERT)"
      ],
      "metadata": {
        "id": "Uvp9GaSzTtCE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_word_test_features = X_test.apply(embeddToBERT)"
      ],
      "metadata": {
        "id": "iCGqOYoaRDu3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature = [x for x in bert_word_training_features.transpose()]\n",
        "bert_word_training_features = np.asarray(feature)\n",
        "feature = [x for x in bert_word_test_features.transpose()]\n",
        "bert_word_test_features = np.asarray(feature)\n",
        "print(bert_word_training_features.shape)"
      ],
      "metadata": {
        "id": "y0tSFggfhxtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f982490c-1daa-47c0-c9b4-326463b22d46"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10268, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmPcHj9hQlvZ"
      },
      "source": [
        "##### SVR "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wlT6-LSlqulz"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg5VrLm0PP9P"
      },
      "source": [
        "###### Tf-idf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ueT9wIuKYEv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87259f88-2513-495a-b2e5-fb8bd75f57c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5915109034267912\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.98      0.74      1523\n",
            "           1       0.47      0.03      0.05      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.53      0.50      0.40      2568\n",
            "weighted avg       0.54      0.59      0.46      2568\n",
            "\n",
            "[[1489   34]\n",
            " [1015   30]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', tfidf),('selector', SelectKBest(chi2, k=100)),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)# fitting the model\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() # using the predefined function to display results of the classification\n",
        "#model.set_params(embedding__max_features=1000)# limiting the max features to 1000 and checking the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fehy6esJBhXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61d1b1cb-1cb8-4180-fccf-d40695d79975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5728193146417445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.79      0.69      1523\n",
            "           1       0.46      0.25      0.33      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.53      0.52      0.51      2568\n",
            "weighted avg       0.55      0.57      0.54      2568\n",
            "\n",
            "[[1205  318]\n",
            " [ 779  266]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', tfidf),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)# fitting the model\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() # using the predefined function to display results of the classification\n",
        "#model.set_params(embedding__max_features=1000)# limiting the max features to 1000 and checking the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9qs0rcNgK3u"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "zfmsezXjgMoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8269f6d4-3471-4b2a-c976-4c1ebd1b41a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.594626168224299\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.99      0.74      1523\n",
            "           1       0.55      0.02      0.04      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.57      0.50      0.39      2568\n",
            "weighted avg       0.58      0.59      0.46      2568\n",
            "\n",
            "[[1506   17]\n",
            " [1024   21]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer',glove),('clf', SVC(random_state=42, kernel='rbf', gamma=0.5, probability=True))]) #('selector', SelectKBest(chi2, k=all)\n",
        "model.fit(X_train, y_train)# fitting the model\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() # using the predefined function to display results of the classification\n",
        "#model.set_params(embedding__max_features=1000)# limiting the max features to 1000 and checking the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGkjSq7lmdJ"
      },
      "source": [
        "###### CV (count vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hQBjZNclpxz"
      },
      "outputs": [],
      "source": [
        "#model = Pipeline([('vectorizer', cv),('selector', SelectKBest(chi2, k=1000)),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "#model.fit(X_train, y_train)\n",
        "#predictions = model.predict(X_test)\n",
        "#print_scores() \n",
        "#model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ba3BJTPpEhC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd03776-e11a-4fc4-ee28-d765b96408f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5502336448598131\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.66      0.64      1523\n",
            "           1       0.44      0.39      0.41      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.53      0.52      0.52      2568\n",
            "weighted avg       0.54      0.55      0.54      2568\n",
            "\n",
            "[[1008  515]\n",
            " [ 640  405]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', cv),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfKG2OwRD_Q2"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aU8_P-HAEFSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc39f010-6bce-4623-8e0a-5521c27a8f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5973520249221184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.98      0.74      1523\n",
            "           1       0.57      0.04      0.08      1045\n",
            "\n",
            "    accuracy                           0.60      2568\n",
            "   macro avg       0.58      0.51      0.41      2568\n",
            "weighted avg       0.59      0.60      0.47      2568\n",
            "\n",
            "[[1490   33]\n",
            " [1001   44]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', w2v),('clf', SVC(random_state=42, kernel='rbf', gamma=1, probability=True)),]) #('selector', SelectKBest(chi2, k=all)) \n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfNqxxVtEGA8"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sgNw8rWIEIJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d81495ef-8449-46cf-a24c-0216e8b72d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5930685358255452\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      1.00      0.74      1523\n",
            "           1       0.00      0.00      0.00      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.30      0.50      0.37      2568\n",
            "weighted avg       0.35      0.59      0.44      2568\n",
            "\n",
            "[[1523    0]\n",
            " [1045    0]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', fasttext),('clf', SVC(random_state=42, kernel='rbf', gamma=1, probability=True)),]) #('selector', SelectKBest(chi2, k=1000))\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "9L1GhRbkAXMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "lXLRzMLJAYdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5374bf-5c7a-479c-f3e6-10063f53e85c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.567367601246106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.81      0.69      1523\n",
            "           1       0.44      0.22      0.29      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.52      0.51      0.49      2568\n",
            "weighted avg       0.53      0.57      0.53      2568\n",
            "\n",
            "[[1228  295]\n",
            " [ 816  229]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3WJ3VH8MS1H"
      },
      "source": [
        "##### LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "woIVZPw8YGtk"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-koJGob-NjS0"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ftv9mhxrMVK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639dcf89-c53b-46e4-be45-354c903d4072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5786604361370716\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.90      0.72      1523\n",
            "           1       0.43      0.11      0.18      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.51      0.51      0.45      2568\n",
            "weighted avg       0.53      0.58      0.50      2568\n",
            "\n",
            "[[1368  155]\n",
            " [ 927  118]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', tfidf),\n",
        "                  ('clf',  LogisticRegression(random_state=42, multi_class='auto', solver='liblinear', penalty='l1')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(embedding__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNRULPR8ENZj"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "U3C8XZVRRYMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b67d180-a3d1-495e-ca63-91fe11d62af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5922897196261683\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.99      0.74      1523\n",
            "           1       0.44      0.01      0.01      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.52      0.50      0.38      2568\n",
            "weighted avg       0.53      0.59      0.45      2568\n",
            "\n",
            "[[1514    9]\n",
            " [1038    7]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', glove),\n",
        "                  ('clf', LogisticRegression(random_state=42,multi_class='auto', solver='liblinear', penalty='l1'))])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(embedding__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5AiS_eoRWA2"
      },
      "source": [
        "###### CV "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ijCnnANtEPMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa84798-b183-4240-8b32-e2e95238d5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5650311526479751\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.75      0.67      1523\n",
            "           1       0.45      0.30      0.36      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.53      0.52      0.51      2568\n",
            "weighted avg       0.54      0.57      0.54      2568\n",
            "\n",
            "[[1140  383]\n",
            " [ 734  311]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', cv),('clf', LogisticRegression(random_state=42,multi_class='auto', solver='liblinear', penalty='l1')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stRUtUyNETSQ"
      },
      "source": [
        "###### w2v "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "5WdblyJlEVMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c0ad4b-d814-408d-a4fe-401bf931892a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5845015576323987\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.92      0.72      1523\n",
            "           1       0.45      0.09      0.15      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.52      0.51      0.44      2568\n",
            "weighted avg       0.54      0.58      0.49      2568\n",
            "\n",
            "[[1406  117]\n",
            " [ 950   95]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', w2v),('clf', LogisticRegression(random_state=42,multi_class='auto', solver='liblinear', penalty='l1')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_zDANh5EVyV"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gs1QI1qFEX_-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96cc7a4-6a62-4862-c85c-0941648a4412"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5969626168224299\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.99      0.74      1523\n",
            "           1       0.65      0.02      0.04      1045\n",
            "\n",
            "    accuracy                           0.60      2568\n",
            "   macro avg       0.62      0.51      0.39      2568\n",
            "weighted avg       0.62      0.60      0.46      2568\n",
            "\n",
            "[[1511   12]\n",
            " [1023   22]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([('vectorizer', fasttext),('clf', LogisticRegression(random_state=42, multi_class='auto', solver='liblinear', penalty='l1'))])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "#model.set_params(embedding__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "rxJ9ynS2Abe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = LogisticRegression(random_state=42, multi_class='auto', solver='liblinear', penalty='l1')\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "OfPmIJAuAcuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7462cd-de6b-4ed1-aec7-23839351bfa5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5689252336448598\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.79      0.69      1523\n",
            "           1       0.45      0.24      0.31      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.52      0.52      0.50      2568\n",
            "weighted avg       0.54      0.57      0.53      2568\n",
            "\n",
            "[[1209  314]\n",
            " [ 793  252]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JziXhDbUMVVW"
      },
      "source": [
        "##### RF "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "L31iMgBgZQy_"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncNNtlL4NmUi"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "iwR8aePnMcA9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df060f4-058e-4a9a-a454-807a9c32d430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "building tree 1 of 50building tree 2 of 50\n",
            "\n",
            "building tree 3 of 50[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 4 of 50[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 5 of 50[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 6 of 50[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 7 of 50[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 8 of 50[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 9 of 50[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.7s\n",
            "building tree 10 of 50[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.7s\n",
            "\n",
            "\n",
            "building tree 11 of 50[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
            "\n",
            "building tree 12 of 50[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.9s\n",
            "\n",
            "building tree 13 of 50[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 14 of 50[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 15 of 50[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 16 of 50[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 17 of 50[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    1.4s\n",
            "\n",
            "building tree 18 of 50[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 19 of 50[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 20 of 50[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 21 of 50[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 22 of 50[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 23 of 50[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    1.9s\n",
            "\n",
            "building tree 24 of 50[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    2.0s\n",
            "\n",
            "building tree 25 of 50[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    2.1s\n",
            "\n",
            "building tree 26 of 50[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.2s\n",
            "\n",
            "building tree 27 of 50[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    2.3s\n",
            "\n",
            "building tree 28 of 50\n",
            "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
            "building tree 29 of 50[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    2.5s\n",
            "\n",
            "building tree 30 of 50[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    2.5s\n",
            "\n",
            "building tree 31 of 50[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    2.6s\n",
            "\n",
            "building tree 32 of 50[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.7s\n",
            "\n",
            "building tree 33 of 50[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    2.8s\n",
            "\n",
            "building tree 34 of 50[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    2.9s\n",
            "\n",
            "building tree 35 of 50[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.0s\n",
            "\n",
            "building tree 36 of 50[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.0s\n",
            "\n",
            "building tree 37 of 50[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    3.2s\n",
            "\n",
            "building tree 38 of 50[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    3.2s\n",
            "\n",
            "building tree 39 of 50[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.3s\n",
            "\n",
            "building tree 40 of 50[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    3.4s\n",
            "\n",
            "building tree 41 of 50[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    3.5s\n",
            "\n",
            "building tree 42 of 50[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    3.6s\n",
            "\n",
            "building tree 43 of 50[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    3.7s\n",
            "\n",
            "building tree 44 of 50[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.8s\n",
            "\n",
            "building tree 45 of 50[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    3.9s\n",
            "\n",
            "building tree 46 of 50[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    3.9s\n",
            "\n",
            "building tree 47 of 50[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    4.0s\n",
            "\n",
            "building tree 48 of 50[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.1s\n",
            "\n",
            "building tree 49 of 50[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    4.2s\n",
            "\n",
            "building tree 50 of 50[Parallel(n_jobs=-1)]: Done  48 out of  50 | elapsed:    4.3s remaining:    0.2s\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  47 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done  48 out of  50 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
            "Accuracy:  0.5771028037383178\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.85      0.70      1523\n",
            "           1       0.45      0.18      0.26      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.53      0.51      0.48      2568\n",
            "weighted avg       0.54      0.58      0.52      2568\n",
            "\n",
            "[[1296  227]\n",
            " [ 859  186]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', tfidf),\n",
        "    ('clf', RandomForestClassifier(random_state=42, verbose=100, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() # using the predefined function to display results of the classification\n",
        "#model.set_params(embedding__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ay6CLu4EfyM"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hEMzEnlaEhQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df468b6-8d5b-40c8-e762-c91aa846b511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "building tree 1 of 50building tree 2 of 50\n",
            "\n",
            "building tree 3 of 50[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "\n",
            "building tree 4 of 50[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
            "\n",
            "building tree 5 of 50[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 6 of 50[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 7 of 50[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.3s\n",
            "\n",
            "building tree 8 of 50[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.3s\n",
            "\n",
            "building tree 9 of 50[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 10 of 50[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 11 of 50[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 12 of 50[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 13 of 50[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 14 of 50[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.6s\n",
            "\n",
            "building tree 15 of 50[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.6s\n",
            "\n",
            "building tree 16 of 50[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.6s\n",
            "\n",
            "building tree 17 of 50[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    0.7s\n",
            "\n",
            "building tree 18 of 50\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.7s\n",
            "building tree 19 of 50[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 20 of 50\n",
            "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.8s\n",
            "building tree 21 of 50[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    0.9s\n",
            "\n",
            "building tree 22 of 50[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    0.9s\n",
            "\n",
            "building tree 23 of 50[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    1.0s\n",
            "\n",
            "building tree 24 of 50[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    1.0s\n",
            "\n",
            "building tree 25 of 50[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 26 of 50[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 27 of 50[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    1.2s\n",
            "\n",
            "building tree 28 of 50[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
            "\n",
            "building tree 29 of 50[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 30 of 50[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 31 of 50[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 32 of 50[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    1.4s\n",
            "\n",
            "building tree 33 of 50[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 34 of 50[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 35 of 50[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 36 of 50[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 37 of 50[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    1.7s\n",
            "\n",
            "building tree 38 of 50[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    1.7s\n",
            "\n",
            "building tree 39 of 50[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 40 of 50[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 41 of 50[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 42 of 50[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    1.9s\n",
            "\n",
            "building tree 43 of 50[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    1.9s\n",
            "\n",
            "building tree 44 of 50[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.9s\n",
            "\n",
            "building tree 45 of 50[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    2.0s\n",
            "\n",
            "building tree 46 of 50[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    2.0s\n",
            "\n",
            "building tree 47 of 50[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    2.1s\n",
            "\n",
            "building tree 48 of 50[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    2.1s\n",
            "\n",
            "building tree 49 of 50[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    2.2s\n",
            "\n",
            "building tree 50 of 50[Parallel(n_jobs=-1)]: Done  48 out of  50 | elapsed:    2.2s remaining:    0.1s\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  47 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  48 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "Accuracy:  0.5751557632398754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.86      0.71      1523\n",
            "           1       0.44      0.16      0.24      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.52      0.51      0.47      2568\n",
            "weighted avg       0.53      0.58      0.52      2568\n",
            "\n",
            "[[1305  218]\n",
            " [ 873  172]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', glove),\n",
        "    ('clf', RandomForestClassifier(random_state=42, verbose=100, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCOnV1F5Eh8d"
      },
      "source": [
        "###### cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ApKBUtTUEjxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf58cce-b516-4d9c-ae1a-db019fe6eb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "building tree 1 of 20\n",
            "building tree 2 of 20\n",
            "building tree 3 of 20[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 4 of 20[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 5 of 20[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 6 of 20[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 7 of 20[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.6s\n",
            "\n",
            "building tree 8 of 20[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.6s\n",
            "\n",
            "building tree 9 of 20[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 10 of 20[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 11 of 20[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
            "\n",
            "building tree 12 of 20[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.0s\n",
            "\n",
            "building tree 13 of 20[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 14 of 20[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.2s\n",
            "\n",
            "building tree 15 of 20[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 16 of 20[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.4s\n",
            "\n",
            "building tree 17 of 20[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 18 of 20[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 19 of 20[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.7s\n",
            "\n",
            "building tree 20 of 20[Parallel(n_jobs=-1)]: Done  18 out of  20 | elapsed:    1.7s remaining:    0.2s\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    1.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
            "Accuracy:  0.5693146417445483\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.83      0.70      1523\n",
            "           1       0.43      0.18      0.26      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.51      0.51      0.48      2568\n",
            "weighted avg       0.53      0.57      0.52      2568\n",
            "\n",
            "[[1270  253]\n",
            " [ 853  192]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', cv),\n",
        "    ('clf', RandomForestClassifier(random_state=42, verbose=100, n_estimators=20, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyWvJkedEkS3"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "P431lXacEmEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1efc353-e9ad-4119-dc67-d55f27911e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "building tree 1 of 50building tree 2 of 50\n",
            "\n",
            "building tree 3 of 50[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "\n",
            "building tree 4 of 50[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
            "\n",
            "building tree 5 of 50[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 6 of 50[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 7 of 50[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 8 of 50[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 9 of 50[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    1.0s\n",
            "\n",
            "building tree 10 of 50[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.0s\n",
            "\n",
            "building tree 11 of 50[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 12 of 50[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 13 of 50[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 14 of 50[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.5s\n",
            "\n",
            "building tree 15 of 50[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.7s\n",
            "\n",
            "building tree 16 of 50[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 17 of 50[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    2.0s\n",
            "\n",
            "building tree 18 of 50[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.1s\n",
            "\n",
            "building tree 19 of 50[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
            "\n",
            "building tree 20 of 50[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.4s\n",
            "\n",
            "building tree 21 of 50[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    2.5s\n",
            "\n",
            "building tree 22 of 50[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    2.6s\n",
            "\n",
            "building tree 23 of 50[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.8s\n",
            "\n",
            "building tree 24 of 50[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    2.9s\n",
            "\n",
            "building tree 25 of 50[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.0s\n",
            "\n",
            "building tree 26 of 50[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.1s\n",
            "\n",
            "building tree 27 of 50[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.3s\n",
            "\n",
            "building tree 28 of 50[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
            "\n",
            "building tree 29 of 50[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.5s\n",
            "\n",
            "building tree 30 of 50[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.7s\n",
            "\n",
            "building tree 31 of 50[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.8s\n",
            "\n",
            "building tree 32 of 50[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    4.0s\n",
            "\n",
            "building tree 33 of 50[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    4.1s\n",
            "\n",
            "building tree 34 of 50[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    4.2s\n",
            "\n",
            "building tree 35 of 50[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.4s\n",
            "\n",
            "building tree 36 of 50[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.5s\n",
            "\n",
            "building tree 37 of 50[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    4.7s\n",
            "\n",
            "building tree 38 of 50[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    4.8s\n",
            "\n",
            "building tree 39 of 50[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    4.9s\n",
            "\n",
            "building tree 40 of 50[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    5.0s\n",
            "\n",
            "building tree 41 of 50[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    5.2s\n",
            "\n",
            "building tree 42 of 50[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    5.3s\n",
            "\n",
            "building tree 43 of 50[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    5.4s\n",
            "\n",
            "building tree 44 of 50[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.6s\n",
            "\n",
            "building tree 45 of 50[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    5.7s\n",
            "\n",
            "building tree 46 of 50[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    5.9s\n",
            "\n",
            "building tree 47 of 50[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    5.9s\n",
            "\n",
            "building tree 48 of 50[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    6.1s\n",
            "\n",
            "building tree 49 of 50[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    6.2s\n",
            "\n",
            "building tree 50 of 50[Parallel(n_jobs=-1)]: Done  48 out of  50 | elapsed:    6.4s remaining:    0.3s\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  47 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  48 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "Accuracy:  0.5852803738317757\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.88      0.72      1523\n",
            "           1       0.47      0.15      0.23      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.54      0.52      0.47      2568\n",
            "weighted avg       0.55      0.59      0.52      2568\n",
            "\n",
            "[[1342  181]\n",
            " [ 884  161]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', w2v),\n",
        "    ('clf', RandomForestClassifier(random_state=42, verbose=100, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC68JIE_Em3i"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5G86al7OEo80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c8f9c6-5fb7-4ddf-8006-cfd9d0dea3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "building tree 1 of 50\n",
            "building tree 2 of 50\n",
            "building tree 3 of 50[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "\n",
            "building tree 4 of 50[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.3s\n",
            "\n",
            "building tree 5 of 50[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.5s\n",
            "\n",
            "building tree 6 of 50[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.6s\n",
            "\n",
            "building tree 7 of 50[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 8 of 50[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 9 of 50[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 10 of 50[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.1s\n",
            "\n",
            "building tree 11 of 50[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
            "\n",
            "building tree 12 of 50[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
            "\n",
            "building tree 13 of 50[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 14 of 50[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 15 of 50[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.9s\n",
            "\n",
            "building tree 16 of 50[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.9s\n",
            "\n",
            "building tree 17 of 50[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    2.1s\n",
            "\n",
            "building tree 18 of 50[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.2s\n",
            "\n",
            "building tree 19 of 50[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.4s\n",
            "\n",
            "building tree 20 of 50[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.4s\n",
            "\n",
            "building tree 21 of 50[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    2.7s\n",
            "\n",
            "building tree 22 of 50\n",
            "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    2.7s\n",
            "building tree 23 of 50[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.0s\n",
            "\n",
            "building tree 24 of 50[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    3.0s\n",
            "\n",
            "building tree 25 of 50[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    3.2s\n",
            "\n",
            "building tree 26 of 50[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    3.3s\n",
            "\n",
            "building tree 27 of 50[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    3.5s\n",
            "\n",
            "building tree 28 of 50[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.5s\n",
            "\n",
            "building tree 29 of 50[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    3.7s\n",
            "\n",
            "building tree 30 of 50[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.8s\n",
            "\n",
            "building tree 31 of 50[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    4.0s\n",
            "\n",
            "building tree 32 of 50[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    4.2s\n",
            "\n",
            "building tree 33 of 50[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    4.2s\n",
            "\n",
            "building tree 34 of 50[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    4.4s\n",
            "\n",
            "building tree 35 of 50[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    4.5s\n",
            "\n",
            "building tree 36 of 50\n",
            "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.7s\n",
            "building tree 37 of 50[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    4.8s\n",
            "\n",
            "building tree 38 of 50[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    4.9s\n",
            "\n",
            "building tree 39 of 50[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.1s\n",
            "\n",
            "building tree 40 of 50[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    5.2s\n",
            "\n",
            "building tree 41 of 50[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    5.4s\n",
            "\n",
            "building tree 42 of 50[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    5.5s\n",
            "\n",
            "building tree 43 of 50[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    5.7s\n",
            "\n",
            "building tree 44 of 50[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.8s\n",
            "\n",
            "building tree 45 of 50[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    6.0s\n",
            "\n",
            "building tree 46 of 50[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    6.0s\n",
            "\n",
            "building tree 47 of 50[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    6.2s\n",
            "\n",
            "building tree 48 of 50[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    6.3s\n",
            "\n",
            "building tree 49 of 50[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:    6.5s\n",
            "\n",
            "building tree 50 of 50[Parallel(n_jobs=-1)]: Done  48 out of  50 | elapsed:    6.6s remaining:    0.3s\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  47 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  48 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "Accuracy:  0.5767133956386293\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.87      0.71      1523\n",
            "           1       0.44      0.15      0.22      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.52      0.51      0.47      2568\n",
            "weighted avg       0.53      0.58      0.51      2568\n",
            "\n",
            "[[1326  197]\n",
            " [ 890  155]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', fasttext),\n",
        "    ('clf', RandomForestClassifier(random_state=42, verbose=100, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "XxCNqBCxAeV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = RandomForestClassifier(random_state=42, verbose=100, n_estimators=50, n_jobs=-1)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "KjDTvPGnAfg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d8a9f9-56be-4abe-f87c-ddccbe2a8f73"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "building tree 1 of 50building tree 2 of 50\n",
            "\n",
            "building tree 3 of 50[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 4 of 50[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.4s\n",
            "\n",
            "building tree 5 of 50[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 6 of 50[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.8s\n",
            "\n",
            "building tree 7 of 50[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    1.2s\n",
            "\n",
            "building tree 8 of 50[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:    1.3s\n",
            "\n",
            "building tree 9 of 50[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:    1.6s\n",
            "\n",
            "building tree 10 of 50[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    1.8s\n",
            "\n",
            "building tree 11 of 50[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.0s\n",
            "\n",
            "building tree 12 of 50[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    2.2s\n",
            "\n",
            "building tree 13 of 50[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:    2.5s\n",
            "\n",
            "building tree 14 of 50[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    2.7s\n",
            "\n",
            "building tree 15 of 50[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    2.9s\n",
            "\n",
            "building tree 16 of 50[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.2s\n",
            "\n",
            "building tree 17 of 50[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:    3.3s\n",
            "\n",
            "building tree 18 of 50[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    3.6s\n",
            "\n",
            "building tree 19 of 50[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    3.7s\n",
            "\n",
            "building tree 20 of 50[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.0s\n",
            "\n",
            "building tree 21 of 50[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    4.1s\n",
            "\n",
            "building tree 22 of 50[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:    4.5s\n",
            "\n",
            "building tree 23 of 50[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    4.6s\n",
            "\n",
            "building tree 24 of 50[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:    4.9s\n",
            "\n",
            "building tree 25 of 50[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:    5.0s\n",
            "\n",
            "building tree 26 of 50\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    5.2s\n",
            "building tree 27 of 50[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.4s\n",
            "\n",
            "building tree 28 of 50[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.6s\n",
            "\n",
            "building tree 29 of 50[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:    5.8s\n",
            "\n",
            "building tree 30 of 50[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    6.1s\n",
            "\n",
            "building tree 31 of 50[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.3s\n",
            "\n",
            "building tree 32 of 50[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    6.5s\n",
            "\n",
            "building tree 33 of 50[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:    6.8s\n",
            "\n",
            "building tree 34 of 50[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    6.9s\n",
            "\n",
            "building tree 35 of 50[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    7.2s\n",
            "\n",
            "building tree 36 of 50[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.3s\n",
            "\n",
            "building tree 37 of 50[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:    7.6s\n",
            "\n",
            "building tree 38 of 50[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    7.7s\n",
            "\n",
            "building tree 39 of 50[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.9s\n",
            "\n",
            "building tree 40 of 50[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    8.1s\n",
            "\n",
            "building tree 41 of 50[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:    8.4s\n",
            "\n",
            "building tree 42 of 50[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    8.6s\n",
            "\n",
            "building tree 43 of 50[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    8.8s\n",
            "\n",
            "building tree 44 of 50[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.9s\n",
            "\n",
            "building tree 45 of 50[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:    9.2s\n",
            "\n",
            "building tree 46 of 50[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    9.4s\n",
            "\n",
            "building tree 47 of 50[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    9.5s\n",
            "\n",
            "building tree 48 of 50[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    9.8s\n",
            "\n",
            "building tree 49 of 50[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:   10.0s\n",
            "\n",
            "building tree 50 of 50[Parallel(n_jobs=-1)]: Done  48 out of  50 | elapsed:   10.2s remaining:    0.4s\n",
            "\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.5s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   10.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  47 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  48 out of  50 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   3 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   6 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   7 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   8 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done   9 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  10 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  11 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  12 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  13 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  15 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  16 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  17 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  18 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  19 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  20 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  21 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  22 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  23 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  24 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  25 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  26 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  27 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  29 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  30 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  31 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  32 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  33 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  34 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  35 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  36 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  37 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  38 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  39 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  40 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  41 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  42 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  43 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  44 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  45 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  47 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  48 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
            "Accuracy:  0.5868380062305296\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.89      0.72      1523\n",
            "           1       0.48      0.15      0.23      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.54      0.52      0.47      2568\n",
            "weighted avg       0.55      0.59      0.52      2568\n",
            "\n",
            "[[1348  175]\n",
            " [ 886  159]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hlRrKvBhAfof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDZpWdDxMcO9"
      },
      "source": [
        "##### NB "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jc7Avv68LKWG"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RPOSUxLNnV2"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nqdP86NdMdiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe758360-dff7-4f4a-85d0-68d5badfa234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5611370716510904\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.69      0.65      1523\n",
            "           1       0.45      0.38      0.41      1045\n",
            "\n",
            "    accuracy                           0.56      2568\n",
            "   macro avg       0.53      0.53      0.53      2568\n",
            "weighted avg       0.55      0.56      0.55      2568\n",
            "\n",
            "[[1046  477]\n",
            " [ 650  395]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', tfidf),\n",
        "    ('clf', MultinomialNB(alpha=0.5, fit_prior=False)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o60rUEN2Er2k"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ogNBg9DtEtr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5717b77f-13c9-46ad-9c0e-d6cd2ac6bf36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5942367601246106\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.93      0.73      1523\n",
            "           1       0.51      0.11      0.18      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.55      0.52      0.46      2568\n",
            "weighted avg       0.56      0.59      0.51      2568\n",
            "\n",
            "[[1411  112]\n",
            " [ 930  115]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', glove),\n",
        "    ('clf', BernoulliNB(alpha=0.1, fit_prior=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLnQdaV8EuLU"
      },
      "source": [
        "###### cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "HbECqbRrEvte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059b7c56-1c2f-446b-a7fb-8a3fddd6c252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5607476635514018\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.67      0.65      1523\n",
            "           1       0.45      0.40      0.42      1045\n",
            "\n",
            "    accuracy                           0.56      2568\n",
            "   macro avg       0.54      0.53      0.53      2568\n",
            "weighted avg       0.55      0.56      0.55      2568\n",
            "\n",
            "[[1026  497]\n",
            " [ 631  414]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', cv),\n",
        "    ('clf', MultinomialNB(alpha=1, fit_prior=False)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "883K9lFTEwbh"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "yT4q6o4IEyFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed12282-5d47-46ba-e42c-5b2d24ce34cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5447819314641744\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.64      0.63      1523\n",
            "           1       0.44      0.40      0.42      1045\n",
            "\n",
            "    accuracy                           0.54      2568\n",
            "   macro avg       0.52      0.52      0.52      2568\n",
            "weighted avg       0.54      0.54      0.54      2568\n",
            "\n",
            "[[977 546]\n",
            " [623 422]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', w2v),\n",
        "    ('clf', BernoulliNB(alpha=0.5, fit_prior=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUz31jIzEykl"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "z40jM3Q2E0j-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeee92f2-e756-443c-a6e2-c62c31c4c27e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5549065420560748\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.66      0.64      1523\n",
            "           1       0.45      0.41      0.43      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.53      0.53      0.53      2568\n",
            "weighted avg       0.55      0.55      0.55      2568\n",
            "\n",
            "[[1000  523]\n",
            " [ 620  425]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', fasttext),\n",
        "    ('clf', BernoulliNB(alpha=1, fit_prior=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "0Q7Ht1X8AhNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = BernoulliNB(alpha=0.1, fit_prior=True)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "zEbOSk8iAigF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b77c664d-1188-4511-d415-b84bcbf961ed"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5490654205607477\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.58      0.60      1523\n",
            "           1       0.45      0.51      0.48      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.54      0.54      0.54      2568\n",
            "weighted avg       0.56      0.55      0.55      2568\n",
            "\n",
            "[[880 643]\n",
            " [515 530]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0NB6QQxNVg3"
      },
      "source": [
        "##### MLP "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "3qph4vFFNLj0"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID916oOXNpCw"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "NXMg0YEjNWyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82a844d-b4ef-4375-f260-80c1cf4dc41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5323208722741433\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.61      0.61      1523\n",
            "           1       0.42      0.41      0.42      1045\n",
            "\n",
            "    accuracy                           0.53      2568\n",
            "   macro avg       0.51      0.51      0.51      2568\n",
            "weighted avg       0.53      0.53      0.53      2568\n",
            "\n",
            "[[934 589]\n",
            " [612 433]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', tfidf),\n",
        "    ('clf',  MLPClassifier(random_state=42, batch_size=20, max_iter=40,\n",
        "                                 activation='logistic', solver='adam')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzRbzwHsJNl_"
      },
      "source": [
        "###### Glove "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "4879ZBfvJPlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8511cef-42d4-4f5b-f383-650884d7aef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.57398753894081\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.85      0.70      1523\n",
            "           1       0.44      0.18      0.25      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.52      0.51      0.48      2568\n",
            "weighted avg       0.54      0.57      0.52      2568\n",
            "\n",
            "[[1287  236]\n",
            " [ 858  187]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', glove),\n",
        "    ('clf',  MLPClassifier(random_state=42, batch_size=20, max_iter=40, activation='relu', solver='adam')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmKOwYlbJQCo"
      },
      "source": [
        "###### cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "aNCnmOcpJRXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dca6ce-d5c9-409c-d978-1cd46bfbcc11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5463395638629284\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.64      0.63      1523\n",
            "           1       0.44      0.41      0.42      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.53      0.53      0.53      2568\n",
            "weighted avg       0.54      0.55      0.54      2568\n",
            "\n",
            "[[973 550]\n",
            " [615 430]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', cv),\n",
        "    ('clf',   MLPClassifier(random_state=42, batch_size=20, max_iter=40,\n",
        "                                 activation='relu', solver='lbfgs')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKQB__g7JR0Q"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "NEYE_PTrJTX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9101d8dd-fe1b-4ffb-dc65-b9ca9b4f72db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5529595015576324\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.71      0.65      1523\n",
            "           1       0.43      0.32      0.37      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.52      0.52      0.51      2568\n",
            "weighted avg       0.53      0.55      0.54      2568\n",
            "\n",
            "[[1085  438]\n",
            " [ 710  335]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', w2v),\n",
        "    ('clf',  MLPClassifier(random_state=42, batch_size=20, max_iter=40,\n",
        "                                 activation='relu', solver='adam')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6oHnEXDJT4W"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LPMZ3NZdJVuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6926c2af-2e15-4610-b095-ce9687f73f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5545171339563862\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.77      0.67      1523\n",
            "           1       0.42      0.24      0.31      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.51      0.51      0.49      2568\n",
            "weighted avg       0.52      0.55      0.52      2568\n",
            "\n",
            "[[1172  351]\n",
            " [ 793  252]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', fasttext),\n",
        "    ('clf',  MLPClassifier(random_state=42, batch_size=20, max_iter=40, activation='relu', solver='adam')),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "5mwU8X-yAj2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = MLPClassifier(random_state=42, batch_size=20, max_iter=40,activation='logistic', solver='adam')\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "9y2rTD1hAlBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aaaebb-b039-4ce2-eec3-dff4b51ab811"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5607476635514018\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.63      0.63      1523\n",
            "           1       0.46      0.46      0.46      1045\n",
            "\n",
            "    accuracy                           0.56      2568\n",
            "   macro avg       0.54      0.54      0.54      2568\n",
            "weighted avg       0.56      0.56      0.56      2568\n",
            "\n",
            "[[963 560]\n",
            " [568 477]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjsmiuqNI4M"
      },
      "source": [
        "##### EXTRA classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "WOxUUPwROwx5"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i69UKpZCNqeD"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "FRfTeL_2NLPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2004bcb5-cba1-4fd5-da4a-cbba6e64d396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5751557632398754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.81      0.69      1523\n",
            "           1       0.46      0.23      0.30      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.53      0.52      0.50      2568\n",
            "weighted avg       0.54      0.58      0.53      2568\n",
            "\n",
            "[[1241  282]\n",
            " [ 809  236]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', tfidf),\n",
        "    ('clf',  ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyjIucEIJYJA"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "PsqxuNUaJccx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bcba7f-61e7-4c63-c8bd-90d783ff898c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5864485981308412\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.88      0.72      1523\n",
            "           1       0.48      0.16      0.23      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.54      0.52      0.48      2568\n",
            "weighted avg       0.55      0.59      0.52      2568\n",
            "\n",
            "[[1343  180]\n",
            " [ 882  163]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', glove),\n",
        "    ('clf',  ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlDvBDobJc10"
      },
      "source": [
        "###### cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "nGZdmYtxJeJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bed15369-af72-4a09-a18d-ef7309dcaee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5681464174454829\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.78      0.68      1523\n",
            "           1       0.45      0.27      0.33      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.53      0.52      0.51      2568\n",
            "weighted avg       0.54      0.57      0.54      2568\n",
            "\n",
            "[[1181  342]\n",
            " [ 767  278]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', cv),\n",
        "    ('clf',   ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpdDwPtQJewL"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Prdz1T4BJgs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed1d51a7-1b62-4341-b020-6981af7facfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5903426791277259\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.91      0.72      1523\n",
            "           1       0.49      0.13      0.21      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.55      0.52      0.47      2568\n",
            "weighted avg       0.56      0.59      0.51      2568\n",
            "\n",
            "[[1379  144]\n",
            " [ 908  137]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', w2v),\n",
        "    ('clf',   ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfFS3WetJhEv"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "q2yDHyE3JjRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7c918c-53d9-4e8c-ae5c-8d1b99c7a24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5763239875389408\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.89      0.71      1523\n",
            "           1       0.43      0.12      0.19      1045\n",
            "\n",
            "    accuracy                           0.58      2568\n",
            "   macro avg       0.51      0.50      0.45      2568\n",
            "weighted avg       0.53      0.58      0.50      2568\n",
            "\n",
            "[[1356  167]\n",
            " [ 921  124]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', fasttext),\n",
        "    ('clf',  ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "poVROGZiAmZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)\n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "-3u7XyjJAnli",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee572345-a15f-4673-f53d-bee01b81aeff"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.588006230529595\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.90      0.72      1523\n",
            "           1       0.48      0.13      0.20      1045\n",
            "\n",
            "    accuracy                           0.59      2568\n",
            "   macro avg       0.54      0.52      0.46      2568\n",
            "weighted avg       0.55      0.59      0.51      2568\n",
            "\n",
            "[[1377  146]\n",
            " [ 912  133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dVxAQQ3NdiP"
      },
      "source": [
        "##### CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZEavBjINsKk"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx_rFAWzNes4"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', CountVectorizer(analyzer='word',preprocessor=preprocess,tokenizer=Tokenizer,stop_words=stopwords_list)),\n",
        "    ('norm2', TfidfTransformer(norm=None)),\n",
        "    ('selector', SelectKBest(chi2, k=1000)),\n",
        "    ('clf',  ),\n",
        "])#analyzer='word', lowercase=True, use_idf=True, stop_words='english\n",
        "# fitting the model\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() # using the predefined function to display results of the classification\n",
        "# limiting the max features to 1000 and checking the model\n",
        "model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9eHJL9rJktz"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JUAnVWbJm7k"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([('vectorizer', cv),('selector', SelectKBest(chi2, k=1000)),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGgT0feaJnXC"
      },
      "source": [
        "###### cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vnoGJj6Joo3"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([('vectorizer', cv),('selector', SelectKBest(chi2, k=1000)),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuhL0lNsJpAe"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOyj42_IJqyR"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([('vectorizer', cv),('selector', SelectKBest(chi2, k=1000)),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCv417GhJrPp"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx6pYcxUJtOQ"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([('vectorizer', cv),('selector', SelectKBest(chi2, k=1000)),('clf', SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores() \n",
        "model.set_params(vectorizer__max_features=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "CE52o6z3Ao2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "c9HK4CJvAqDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhjst2gRMgD5"
      },
      "source": [
        "##### KNN "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "JIX7qYKySjdM"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzodihFPNuBw"
      },
      "source": [
        "###### tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "fGvrIdpWMh47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f151940-f5a6-4f39-b6de-af8920ddb60c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5471183800623053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.70      0.65      1523\n",
            "           1       0.43      0.33      0.37      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.51      0.51      0.51      2568\n",
            "weighted avg       0.53      0.55      0.53      2568\n",
            "\n",
            "[[1061  462]\n",
            " [ 701  344]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', tfidf),\n",
        "    ('clf',  KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE4L2jUvJuxd"
      },
      "source": [
        "###### Glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "1XMac7LyJxDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6ed5be-5c53-4e1a-b6ea-7d8a05fc7aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5486760124610592\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.68      0.64      1523\n",
            "           1       0.43      0.35      0.39      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.52      0.52      0.52      2568\n",
            "weighted avg       0.54      0.55      0.54      2568\n",
            "\n",
            "[[1039  484]\n",
            " [ 675  370]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', glove),\n",
        "    ('clf',   KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-Ht5RDXJxg9"
      },
      "source": [
        "###### cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "rnWJI-c7Jy5Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3de880-dfd2-41b1-bc44-d9e02c4f4d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5654205607476636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.81      0.69      1523\n",
            "           1       0.43      0.21      0.28      1045\n",
            "\n",
            "    accuracy                           0.57      2568\n",
            "   macro avg       0.51      0.51      0.48      2568\n",
            "weighted avg       0.53      0.57      0.52      2568\n",
            "\n",
            "[[1235  288]\n",
            " [ 828  217]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', cv),\n",
        "    ('clf',   KNeighborsClassifier(n_neighbors=3, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiCNk9dJzU0"
      },
      "source": [
        "###### w2v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "A6p_VQxpJ2YW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd05614-602f-45af-8e86-83e147504cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5521806853582555\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.72      0.66      1523\n",
            "           1       0.43      0.31      0.36      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.52      0.51      0.51      2568\n",
            "weighted avg       0.53      0.55      0.54      2568\n",
            "\n",
            "[[1095  428]\n",
            " [ 722  323]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', w2v),\n",
        "    ('clf',  KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB3DFpiEJ1pf"
      },
      "source": [
        "###### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "33PIWKxyJ5KC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93e6261-7d9c-46a2-efad-5ed522372759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5541277258566978\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.71      0.65      1523\n",
            "           1       0.44      0.33      0.37      1045\n",
            "\n",
            "    accuracy                           0.55      2568\n",
            "   macro avg       0.52      0.52      0.51      2568\n",
            "weighted avg       0.54      0.55      0.54      2568\n",
            "\n",
            "[[1080  443]\n",
            " [ 702  343]]\n"
          ]
        }
      ],
      "source": [
        "model = Pipeline([\n",
        "    ('vectorizer', fasttext),\n",
        "    ('clf',  KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),])\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "print_scores()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### BERT"
      ],
      "metadata": {
        "id": "7_6_NrKAArqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "aHahRZkIAs0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e46f4eb-f14c-4bd2-9f6a-8b523f39c214"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.5634735202492211\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.70      0.65      1523\n",
            "           1       0.46      0.37      0.41      1045\n",
            "\n",
            "    accuracy                           0.56      2568\n",
            "   macro avg       0.54      0.53      0.53      2568\n",
            "weighted avg       0.55      0.56      0.55      2568\n",
            "\n",
            "[[1060  463]\n",
            " [ 658  387]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modelos P/ 6 classes "
      ],
      "metadata": {
        "id": "tWhJuwvB9nQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "train=pd.DataFrame(dataset['train'])\n",
        "test=pd.DataFrame(dataset['test'])\n",
        "val=pd.DataFrame(dataset['validation'])\n",
        "print(train.shape,test.shape,val.shape)\n",
        "df_raw = pd.concat([train, test, val], axis=0, sort=False)\n",
        "df_raw = df_raw.sample(frac=1).reset_index()\n",
        "print(train['label'].unique())\n",
        "print(test['label'].unique())\n",
        "print(val['label'].unique())\n",
        "# specifying features and labels\n",
        "X= df_raw['statement']\n",
        "y=df_raw['label']\n",
        "from sklearn.model_selection import train_test_split\n",
        "# specifying train and test split with ratio of 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 0, stratify=y)\n",
        "print(len(X_train), len(X_test))\n",
        "print(len(y_train), len(y_test))"
      ],
      "metadata": {
        "id": "oyULpD6r-kGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelos Bert "
      ],
      "metadata": {
        "id": "B5uGQHvl9rCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_word_training_features = X_train.apply(embeddToBERT)\n",
        "bert_word_test_features = X_test.apply(embeddToBERT)\n",
        "feature = [x for x in bert_word_training_features.transpose()]\n",
        "bert_word_training_features = np.asarray(feature)\n",
        "feature = [x for x in bert_word_test_features.transpose()]\n",
        "bert_word_test_features = np.asarray(feature)\n",
        "print(bert_word_training_features.shape)"
      ],
      "metadata": {
        "id": "ty_l3qkW9qW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = SVC(random_state=42, kernel='linear', gamma=0.1, probability=True)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "t-Su4sKb-4j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = LogisticRegression(random_state=42, multi_class='auto', solver='liblinear', penalty='l1')\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "rOLqSMl9-4rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = RandomForestClassifier(random_state=42, verbose=100, n_estimators=50, n_jobs=-1)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "I3tU-ZDj-4zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ithub base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = BernoulliNB(alpha=0.1, fit_prior=True)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "xZ2JLHTG-47K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = MLPClassifier(random_state=42, batch_size=20, max_iter=40,activation='logistic', solver='adam')\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "HA7U7Jpc-5C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = ExtraTreesClassifier(random_state=42, n_estimators=50, n_jobs=-1)\n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "VlfIhO02-5Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github base : https://github.com/prathameshmahankal/Fake-News-Detection-Using-BERT/blob/main/notebooks/train.ipynb \n",
        "model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "# Training \n",
        "model.fit(bert_word_training_features, y_train)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "# Evaluation\n",
        "predictions = model.predict(bert_word_test_features)\n",
        "#y_prob_bert_words_svm = model.decision_function(bert_word_test_features)\n",
        "print_scores()"
      ],
      "metadata": {
        "id": "beL9gMsb-5Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XmYExWLn-5Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0YjYq-J2ce_"
      },
      "source": [
        "### *EXTRAS*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qaDp_A5VQtw"
      },
      "source": [
        "### Diversity Analysis "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFiv-b6KVYwk",
        "outputId": "3e2d66a9-c8ca-4499-815d-c099cef9204f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting deslib\n",
            "  Downloading DESlib-0.3.5-py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from deslib) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from deslib) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from deslib) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->deslib) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->deslib) (3.0.0)\n",
            "Installing collected packages: deslib\n",
            "Successfully installed deslib-0.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install deslib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeI1ijzvVrQy",
        "outputId": "8c630869-d7ed-45e2-8f62-706427276e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting umap\n",
            "  Downloading umap-0.1.1.tar.gz (3.2 kB)\n",
            "Building wheels for collected packages: umap\n",
            "  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3564 sha256=9995b5cd89e760dcf096249f0930c87c1069b25211e6f607b4b47c0015d03721\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/55/85/945cfb3d67373767e4dc3e9629300a926edde52633df4f0efe\n",
            "Successfully built umap\n",
            "Installing collected packages: umap\n",
            "Successfully installed umap-0.1.1\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 876 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.5.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from umap-learn) (4.62.3)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->umap-learn) (3.0.0)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82709 sha256=5b14426ff4ceb3f18f7654554b3b06a63f4e101863129305106d57d2207e5dc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.5-py3-none-any.whl size=52603 sha256=02f9123c3b4378668a0f5d9febf135e8d307c2512cc788a880bc0eb8635a9f8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/e9/33/04db1436df0757c42fda8ea6796d7a8586e23c85fac355f476\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.5 umap-learn-0.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install umap\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zu-6ztJJVPH9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.manifold import MDS, TSNE\n",
        "from deslib.util.diversity import double_fault\n",
        "import matplotlib.lines as mlines\n",
        "#from umap import UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh1b9i1GV3bQ",
        "outputId": "c384057e-efeb-472e-fe9e-c95875cc7740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting umap-learn==0.3.10\n",
            "  Downloading umap-learn-0.3.10.tar.gz (40 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (1.4.1)\n",
            "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.3.10) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.37->umap-learn==0.3.10) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.37->umap-learn==0.3.10) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->umap-learn==0.3.10) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.16->umap-learn==0.3.10) (1.1.0)\n",
            "Building wheels for collected packages: umap-learn\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.3.10-py3-none-any.whl size=38883 sha256=8ba8b52ff417dffb860253b4c04b008a02db4d91751f0c4f908096e52f5cc2e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/d0/8f/9e64bfc5ed0645f89b639196bef92daf5c704285133efce12f\n",
            "Successfully built umap-learn\n",
            "Installing collected packages: umap-learn\n",
            "  Attempting uninstall: umap-learn\n",
            "    Found existing installation: umap-learn 0.5.2\n",
            "    Uninstalling umap-learn-0.5.2:\n",
            "      Successfully uninstalled umap-learn-0.5.2\n",
            "Successfully installed umap-learn-0.3.10\n"
          ]
        }
      ],
      "source": [
        "!pip install 'umap-learn==0.3.10'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV23Hc6MV7YW"
      },
      "outputs": [],
      "source": [
        "import umap.umap_ as umap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JEnuLjFV7dr"
      },
      "outputs": [],
      "source": [
        "from umap.umap_ import UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnXZednkV7h2"
      },
      "outputs": [],
      "source": [
        "def compute_pairwise_diversity_matrix(targets, prediction_matrix, diversity_func):\n",
        "    n_classifiers = prediction_matrix.shape[1]\n",
        "    diversity = np.zeros((n_classifiers, n_classifiers))\n",
        "    for clf_index in range(n_classifiers):\n",
        "        for clf_index2 in range(clf_index + 1, n_classifiers):\n",
        "            this_diversity = diversity_func(targets,\n",
        "                                            prediction_matrix[:, clf_index],\n",
        "                                            prediction_matrix[:, clf_index2])\n",
        "\n",
        "            diversity[clf_index, clf_index2] = this_diversity\n",
        "            diversity[clf_index2, clf_index] = this_diversity\n",
        "\n",
        "    return diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8m1qgziWnk7"
      },
      "outputs": [],
      "source": [
        "def compute_matrix_embedding(dataset, n_classifiers, n_features, method='mds', n_neighbors=5, min_dist=0.7\n",
        "):\n",
        "    D = compute_pairwise_diversity_matrix(y.to_numpy(), X.to_numpy(), double_fault)\n",
        "    D = 1/D\n",
        "    D[D==np.inf] = 0\n",
        "    if method == 'mds':\n",
        "        method = MDS(dissimilarity='precomputed', random_state=123456987, n_init=20, max_iter=100000)\n",
        "    elif method == 'tsne':\n",
        "        method = TSNE(perplexity=25, init='pca', random_state=42, early_exaggeration=50, \n",
        "                      learning_rate=200, n_iter=2500, angle=0.5)\n",
        "    else:        \n",
        "        method = UMAP(n_neighbors=2, metric='euclidean', random_state=123456987, min_dist=0.7, n_components=2,)\n",
        "    D_tilde = method.fit_transform(D)\n",
        "    D_tilde = D_tilde.reshape(n_classifiers, n_features, 2)\n",
        "    return D_tilde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNoh0Gk2XJ0h"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def plot_diversity(D_changed, method_tmp, dataset, title):\n",
        "    s = 100\n",
        "    colors = {}\n",
        "    colors[0] = '#DAA520'\n",
        "    colors[1] = '#FF0000'\n",
        "    colors[2] = '#0000FF'\n",
        "    colors[3] = '#228B22'\n",
        "    colors[4] = '#000000'\n",
        "    markers = {}\n",
        "    markers[0] = 'X'\n",
        "    markers[1] = 'd'\n",
        "    markers[2] = '*'\n",
        "    markers[3] = \"^\"\n",
        "    markers[4] = 'o'\n",
        "    n_classifiers, n_features, _ = D_changed.shape\n",
        "    plt.figure(figsize=(15,10))\n",
        "    method=0\n",
        "    for idx in range(n_classifiers):\n",
        "        for idx2 in range(n_features):\n",
        "            x, y = D_changed[idx,idx2, 0], D_changed[idx,idx2, 1]\n",
        "            plt.scatter(x, y, color=colors[idx2], s=s, lw=0, marker=markers[idx2])\n",
        "            plt.annotate(method_tmp[method], xy=(x, y), textcoords='offset points', xytext=(5, 15), ha='right', va='top')  \n",
        "            method += 1\n",
        "    \n",
        "    m1 = mlines.Line2D([], [], color=colors[0], marker=markers[0], linestyle='None', markersize=10, label='CV')\n",
        "    m2 = mlines.Line2D([], [], color=colors[1], marker=markers[1], linestyle='None', markersize=10, label='TFIDF')\n",
        "    m3 = mlines.Line2D([], [], color=colors[2], marker=markers[2], linestyle='None', markersize=10, label='Glove')\n",
        "    m4 = mlines.Line2D([], [], color=colors[3], marker=markers[3], linestyle='None', markersize=10, label='Word2Vec')\n",
        "    m5 = mlines.Line2D([], [], color=colors[4], marker=markers[4], linestyle='None', markersize=10, label='FastText')\n",
        "    plt.title('CPS ' + dataset+' dataset')\n",
        "    plt.legend(handles=[m1, m2, m3, m4, m5])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(title + \"_\" + dataset_name.upper()+'_dataset.pdf', dpi=450)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La9Ry_W8V7l0",
        "outputId": "f8f49c9b-737c-4d1c-cb7e-205c4c8d4022"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4, 2, 2, ..., 5, 3, 1])"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "S3fLg5jLV7ou",
        "outputId": "aafd4d06-9440-45ab-d3e8-34a76212feef"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-ed2ed59b7688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#label, methods = load_predictions(dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#methods_name = [name.split('-', 1)[0] for name in methods.columns]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mD_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_matrix_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mplot_diversity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_tilde\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethods_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-f846e6d3cd4e>\u001b[0m in \u001b[0;36mcompute_matrix_embedding\u001b[0;34m(dataset, n_classifiers, n_features, method, n_neighbors, min_dist)\u001b[0m\n\u001b[1;32m      1\u001b[0m def compute_matrix_embedding(dataset, n_classifiers, n_features, method='mds', n_neighbors=5, min_dist=0.7\n\u001b[1;32m      2\u001b[0m ):\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pairwise_diversity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdouble_fault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mD\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-701e9722adb6>\u001b[0m in \u001b[0;36mcompute_pairwise_diversity_matrix\u001b[0;34m(targets, prediction_matrix, diversity_func)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_pairwise_diversity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mn_classifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdiversity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classifiers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclf_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclf_index2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "n_classifiers = 1\n",
        "method = 'umap'\n",
        "n_features = 1\n",
        "#label, methods = load_predictions(dataset)\n",
        "#methods_name = [name.split('-', 1)[0] for name in methods.columns]\n",
        "D_tilde = compute_matrix_embedding(dataset, n_classifiers, n_features, method)\n",
        "plot_diversity(D_tilde, methods_name, dataset_name, method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up8OY6SyV7tx"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHu2UX5iV7xM"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOdLECaBMFFR"
      },
      "source": [
        "### Pre processing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TvREmhp6TLw"
      },
      "source": [
        "#### Converting Multiclass into two classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DBCjsJ26WQy"
      },
      "outputs": [],
      "source": [
        "#function for mapping labels \"true, mostly-true, half-true\" to TRUE and \"false, barely-true, pants-fire\" to FAKE.\n",
        "def binary_class_dataset(data):\n",
        "    \n",
        "    data = data.iloc[:, [2, 3]]\n",
        "    data.columns = ['label', 'statement']\n",
        "    Original_labels = {'true': 'True','mostly-true': 'True','half-true': 'True',\n",
        "        'false': 'Fake','barely-true': 'Fake','pants-fire': 'Fake'}\n",
        "    data['label'] = data['label'].map(Original_labels)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUQhkZKOBLQa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lSKt1A_hfZLy",
        "9qaDp_A5VQtw",
        "eOdLECaBMFFR",
        "7TvREmhp6TLw"
      ],
      "name": "LIAR_2.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOnHfDwbcoFDk0oQ0Dc+q3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abffa58378414868a596c9877b68480d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8aefd848688a48e1a0161f26a5d92e17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2354c5d783ea47a581c50d2b89efdd41",
              "IPY_MODEL_59bbbe48656d43fdaa3cc3238bad9d6e",
              "IPY_MODEL_88b2dea02e2c4cd39e269544d1b6343a"
            ]
          }
        },
        "8aefd848688a48e1a0161f26a5d92e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2354c5d783ea47a581c50d2b89efdd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc5852439078473f9e18f70838870903",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f87da839c194548bf5373ded49031d4"
          }
        },
        "59bbbe48656d43fdaa3cc3238bad9d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_409791b5baab4b20bd2273387ccfa42e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2326,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2326,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4482920085ee4ef9adfa93c29aa148da"
          }
        },
        "88b2dea02e2c4cd39e269544d1b6343a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7df972fa53364f838449907908d4283a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6.41k/? [00:00&lt;00:00, 101kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_075f1e2d50894dd280e6eade39f5f13f"
          }
        },
        "bc5852439078473f9e18f70838870903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f87da839c194548bf5373ded49031d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "409791b5baab4b20bd2273387ccfa42e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4482920085ee4ef9adfa93c29aa148da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7df972fa53364f838449907908d4283a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "075f1e2d50894dd280e6eade39f5f13f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95db8eeca9a742898be5edb085dfed29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dba63ea2c583412484434602e3c53802",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e2bb1f86d624c15bdd3b8b43cdad558",
              "IPY_MODEL_223f0b861f6a409bab86811b7ba8eabc",
              "IPY_MODEL_21a77b3015c54aeca55117ce09bcfc44"
            ]
          }
        },
        "dba63ea2c583412484434602e3c53802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e2bb1f86d624c15bdd3b8b43cdad558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2f600dae54a42dfa58e04d7518d9d20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9319f1058b54726a9ad03245405d9f1"
          }
        },
        "223f0b861f6a409bab86811b7ba8eabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bfee3a19bc7042c5bcde541ccc410e44",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1680,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1680,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1502946c43f6438fb7849d67d5b73a9e"
          }
        },
        "21a77b3015c54aeca55117ce09bcfc44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ba702c243194c3cb86bc04e1649295f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.03k/? [00:00&lt;00:00, 119kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_000b3b353edb4a9d8894eb64d57cea85"
          }
        },
        "e2f600dae54a42dfa58e04d7518d9d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9319f1058b54726a9ad03245405d9f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfee3a19bc7042c5bcde541ccc410e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1502946c43f6438fb7849d67d5b73a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ba702c243194c3cb86bc04e1649295f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "000b3b353edb4a9d8894eb64d57cea85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65d27b3f4e664af8bf5865fab5729fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe202ffd42c34a9e963068d47c57d630",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_feb2c1dc15c7431cabe04863e9d68ad4",
              "IPY_MODEL_7c5cbf918226461dbbcd247d171bcfed",
              "IPY_MODEL_190db26640f04851b7ee6d09db179aef"
            ]
          }
        },
        "fe202ffd42c34a9e963068d47c57d630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "feb2c1dc15c7431cabe04863e9d68ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15715bfb8fec48408823bbde096d0b04",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b6cd5cf0f2e4496a63744e2ba9291c1"
          }
        },
        "7c5cbf918226461dbbcd247d171bcfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_448c1dddde4c4da0acf25f38a4758288",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1013571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1013571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27f30893cd5e483095350bd37ee48f34"
          }
        },
        "190db26640f04851b7ee6d09db179aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02400aa009cb4cae928335ff788cc9bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.01M/1.01M [00:01&lt;00:00, 1.43MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21142b95acff4d209c92d89160f28e04"
          }
        },
        "15715bfb8fec48408823bbde096d0b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b6cd5cf0f2e4496a63744e2ba9291c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "448c1dddde4c4da0acf25f38a4758288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27f30893cd5e483095350bd37ee48f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02400aa009cb4cae928335ff788cc9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21142b95acff4d209c92d89160f28e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fab994bbe1a547dcb4b6ff7a972df0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_867959911fea40da88bd4e139c8ad2b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46255ddacb544faebd913a229f676c11",
              "IPY_MODEL_4d2ddd01928042e6bb7c94acfa473381",
              "IPY_MODEL_596c34e1416e45d4934c954998eeb1a7"
            ]
          }
        },
        "867959911fea40da88bd4e139c8ad2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46255ddacb544faebd913a229f676c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3aa4a01d43d44d498fb6c4b3738db511",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16ee1d781f894613af37fc4f4c22d1f3"
          }
        },
        "4d2ddd01928042e6bb7c94acfa473381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4ac0b37eb98c4025916b31353d485231",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b46653b9e3f843c1b29dd842b633bb08"
          }
        },
        "596c34e1416e45d4934c954998eeb1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c19b582204c045feb64ac0dd0737a200",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10065/0 [00:01&lt;00:00, 5366.95 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bbee970689640488aafc44260794f06"
          }
        },
        "3aa4a01d43d44d498fb6c4b3738db511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16ee1d781f894613af37fc4f4c22d1f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac0b37eb98c4025916b31353d485231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b46653b9e3f843c1b29dd842b633bb08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c19b582204c045feb64ac0dd0737a200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bbee970689640488aafc44260794f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c19fc6db6bb94d4dae1a1927c7b9dc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_56ab9f7e95e24eb480592fa662579d3c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a58d1824c8d2403a88000aa0a1b40a73",
              "IPY_MODEL_d35ec4a7e7454cf382c46160b2323ab5",
              "IPY_MODEL_d13559e54a09465eb460c676c2b96b80"
            ]
          }
        },
        "56ab9f7e95e24eb480592fa662579d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a58d1824c8d2403a88000aa0a1b40a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_472b4484fe3b4da3aaefd86b3396d85c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d59047c681c40b296c0c6995f13f846"
          }
        },
        "d35ec4a7e7454cf382c46160b2323ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b4d45012ffd4f48b4304270726446b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a38b517388c040e79f58815e69c4de35"
          }
        },
        "d13559e54a09465eb460c676c2b96b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_234d8553efc741499a4c04d80fa16740",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 948/0 [00:00&lt;00:00, 5086.86 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d169e26994a2478abd5de445eab29e2d"
          }
        },
        "472b4484fe3b4da3aaefd86b3396d85c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d59047c681c40b296c0c6995f13f846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b4d45012ffd4f48b4304270726446b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a38b517388c040e79f58815e69c4de35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "234d8553efc741499a4c04d80fa16740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d169e26994a2478abd5de445eab29e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0361234090894c7785c1f25a451b3713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7f7abc2a1e6a489d99d916ec65db21f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3fd1b52a7a64dfc89ad89c4104a324e",
              "IPY_MODEL_5e74b2c5c0fb47b393c0bf976d6e147f",
              "IPY_MODEL_db8a090a1d894a85a9f9acf623357fb1"
            ]
          }
        },
        "7f7abc2a1e6a489d99d916ec65db21f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3fd1b52a7a64dfc89ad89c4104a324e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e09b7217a4b47fcaf6fa44531444d7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95b378fb1d274dcbb695f4cf3ad31e5d"
          }
        },
        "5e74b2c5c0fb47b393c0bf976d6e147f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_106886a9f2e942899a8587f76d12a581",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72d3da2864de4014852d5f2662ffa328"
          }
        },
        "db8a090a1d894a85a9f9acf623357fb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2549fa3e6bbe4543b671a29f6dc49e65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 861/0 [00:00&lt;00:00, 2004.40 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d0a2a1a26ff4274813bd3ffdb36d54a"
          }
        },
        "5e09b7217a4b47fcaf6fa44531444d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95b378fb1d274dcbb695f4cf3ad31e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "106886a9f2e942899a8587f76d12a581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72d3da2864de4014852d5f2662ffa328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2549fa3e6bbe4543b671a29f6dc49e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d0a2a1a26ff4274813bd3ffdb36d54a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d660278bce64469a49c46d8a5dff5fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e10f5c909f249bca177f6ad178b8e8e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65bb41b661794bd9ab15d8afff5c5389",
              "IPY_MODEL_9e38e38d9a384510a311a5f2c7b9bc4e",
              "IPY_MODEL_b645087427524d8586ca41811d6b6510"
            ]
          }
        },
        "9e10f5c909f249bca177f6ad178b8e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65bb41b661794bd9ab15d8afff5c5389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d2e28b39d164f8d96934fe38c1ec50c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d08627a111084aa58c89658fe1987ff5"
          }
        },
        "9e38e38d9a384510a311a5f2c7b9bc4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f845f91521c94e269344f490be498eb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20e6ba394c6c4070b4a724b637e21dba"
          }
        },
        "b645087427524d8586ca41811d6b6510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3ddf38054964ac2a1e732ef7d959619",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 53.35it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ad97632bb5445c0ace32ace7de24048"
          }
        },
        "8d2e28b39d164f8d96934fe38c1ec50c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d08627a111084aa58c89658fe1987ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f845f91521c94e269344f490be498eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20e6ba394c6c4070b4a724b637e21dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3ddf38054964ac2a1e732ef7d959619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ad97632bb5445c0ace32ace7de24048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}